{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "import os, numpy as np\n",
    "\n",
    "\n",
    "print('loaded up')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_hidden_file(filename):\n",
    "    if filename.startswith('.'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_images = '/home/steve/Desktop/skin_cancer_detector/Skin_Cancer_NN_Project_Images/2020_data/training_data/archive/'\n",
    "\n",
    "# import required module\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    " \n",
    "# load the image\n",
    "#img = load_img('dog.jpg')\n",
    " \n",
    "# assign directory\n",
    "# directory = 'files'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "training_images = []\n",
    "#testing_images = []\n",
    "# import required module\n",
    "# assign directory\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "display(os.listdir(path_to_images))\n",
    "training_image_file_list = []\n",
    "\n",
    "display('reshaping images')\n",
    "\n",
    "for filename in os.listdir(path_to_images):\n",
    "\n",
    "    f = os.path.join(path_to_images, filename)\n",
    "    \n",
    "    # checking if it is a file\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "    \n",
    "        #print(img.size)\n",
    "        \n",
    "        if f[-4:] == '.JPG' and filename[0] != '.':\n",
    "            #display(f)\n",
    "            #display(type(f))\n",
    "            img = load_img(f)\n",
    "            #print(img.size)\n",
    "            img = tf.image.resize(img,(299,299), method='bilinear')\n",
    "            #img = img.resize((255,255))\n",
    "            arr = img_to_array(img)\n",
    "            training_images.append(arr)\n",
    "            training_image_file_list.append(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#display(training_images[0])\n",
    "#display(len(training_images))\n",
    "display(training_images[:10])\n",
    "\n",
    "display('loaded up')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = '/home/steve/Desktop/skin_cancer_detector/full_training_data/benign'\n",
    "\n",
    "# import required module\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    " \n",
    "# load the image\n",
    "#img = load_img('dog.jpg')\n",
    " \n",
    "# assign directory\n",
    "# directory = 'files'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "training_images = []\n",
    "#testing_images = []\n",
    "# import required module\n",
    "# assign directory\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "display(os.listdir(path_to_images))\n",
    "training_image_file_list = []\n",
    "\n",
    "display('benign!')\n",
    "\n",
    "for filename in os.listdir(path_to_images):\n",
    "\n",
    "    f = os.path.join(path_to_images, filename)\n",
    "    \n",
    "    # checking if it is a file\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "    \n",
    "        #print(img.size)\n",
    "        \n",
    "        if f[-4:] == '.JPG' and filename[0] != '.':\n",
    "            #display(f)\n",
    "            #display(type(f))\n",
    "            img = load_img(f)\n",
    "            #print(img.size)\n",
    "            if img.size != (299,299):\n",
    "                display(img.size) \n",
    "            #img = tf.image.resize(img,(299,299), method='bilinear')\n",
    "            #img = img.resize((255,255))\n",
    "            #arr = img_to_array(img)\n",
    "            #training_images.append(arr)\n",
    "            #training_image_file_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "training_images = []\n",
    "training_image_file_list = []\n",
    "training_data_df = pd.read_csv('training_df.csv')\n",
    "path_to_images = '/home/steve/Desktop/skin_cancer_detector/full_training_data/benign/'\n",
    "\n",
    "display(training_data_df.head(10))\n",
    "\n",
    "for index, row in training_data_df.iterrows():\n",
    "\n",
    "    f = os.path.join(path_to_images, row['changed_filenames'] +'.JPG')\n",
    "    #print(f)\n",
    "    \n",
    "    # checking if it is a file\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "    \n",
    "        #print(f)\n",
    "        #input('stop for a moment')\n",
    "\n",
    "        \n",
    "        img = load_img(f)\n",
    "        img = tf.image.resize(img,(299,299), method='bilinear')\n",
    "        arr = img_to_array(img)\n",
    "        training_images.append(arr)\n",
    "        training_image_file_list.append(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#display(training_images[0])\n",
    "#display(len(training_images))\n",
    "display(training_images[:10])\n",
    "\n",
    "display('loaded up')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('training!')\n",
    "import gc\n",
    "gc.collect()\n",
    "training_images_2 = [tf.image.resize(training_images,(299,299), method='bilinear') ]\n",
    "display('training_images_2_done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "display(len(training_images))\n",
    "\n",
    "display(len(training_image_file_list))\n",
    "\n",
    "zipped_images_and_filenames = zip(training_image_file_list,training_images)\n",
    "list_of_zipped_images_and_filenames = list(zipped_images_and_filenames)\n",
    "#list_of_zipped_images_and_filenames.sort(key=lambda x: x[0])\n",
    "#display(list_of_zipped_images_and_filenames[:10])\n",
    "#compress_and_save_this_to_file = np.array(list_of_zipped_images_and_filenames)\n",
    "#np.savez_compressed('2019_training_images_and_filenames',compress_and_save_this_to_file)\n",
    "\n",
    "whole_data = pd.DataFrame(list_of_zipped_images_and_filenames)\n",
    "whole_data.columns = ['isic_id','image_data']\n",
    "display(whole_data.head(5))\n",
    "\n",
    "whole_data.sort_values(by='isic_id', inplace=True)\n",
    "\n",
    "display(whole_data.head(6))\n",
    "\n",
    "#whole_data.to_csv('2019_training_images_and_filenames.csv', index=False)\n",
    "\n",
    "display(whole_data['isic_id'].to_numpy())\n",
    "\n",
    "display(whole_data['image_data'].to_numpy())\n",
    "\n",
    "save_this = whole_data.to_numpy()\n",
    "\n",
    "np.save('2020_training_data',whole_data)\n",
    "\n",
    "\n",
    "#display(\"TRAINING IMAGE\")\n",
    "#display(training_images[0])\n",
    "#display(whole_data.iloc[5,:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#display(array_to_img(training_images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import array_to_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "whole_data_2 = np.load('2020_training_data.npy',allow_pickle=True)\n",
    "display('loaded up!')\n",
    "img = array_to_img(whole_data_2[0,1])\n",
    "display(whole_data_2[0])\n",
    "display(img)\n",
    "#img = array_to_img(np.array(list(whole_data_2['image_data'][6].replace('\\n',','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "converted_images = []\n",
    "for x in whole_data_2[:,1]:\n",
    "    converted_images.append(x/255.0)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "converted_images = K.constant(whole_data_2[:,1])\n",
    "display(converted_images[0])\n",
    "\n",
    "import matplotlib.pyplot\n",
    "matplotlib.pyplot.rcParams[\"axes.grid\"] = False  #  Remove the grid lines from the image.\n",
    "matplotlib.pyplot.imshow(converted_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "base_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(299, 299, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "# We're trying 2 this time\n",
    "outputs = tf.keras.layers.Dense(2)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical as one_hot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#photos = whole_data_2[:,1]\n",
    "#display(type(photos))\n",
    "\n",
    "label_data = pd.read_csv('2020_training_label_data.csv')['benign_malignant']\n",
    "label_data = label_data.replace('benign',0).replace('malignant',1)\n",
    "\n",
    "display(label_data.head())\n",
    "\n",
    "y_train_hot = one_hot(label_data)\n",
    "\n",
    "label_data = np.array(label_data)[:-2]\n",
    "\n",
    "display(label_data)\n",
    "\n",
    "display('training!')\n",
    "\n",
    "#display(len(converted_images))\n",
    "\n",
    "#display(len(label_data))\n",
    "\n",
    "#display(converted_images[0])\n",
    "#display(converted_images[0].shape)\n",
    "\n",
    "#display(type(training_images))\n",
    "\n",
    "#model.predict(np.array(converted_images[0]))\n",
    "\n",
    "\n",
    "model.fit(training_images_2, label_data, epochs=30,\\\n",
    "         batch_size=100,\\\n",
    "         validation_split=0.2)\n",
    "\n",
    "\"\"\"\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "inception = tf.keras.Model([inception.input], [inception.layers[-2].output]) # manually discard prediction\n",
    "inception.predict(np.array(converted_images[0]))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('skin_cancer_vgg19_2_bits_no_activation.keras', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree, copy\n",
    "from glob import glob\n",
    "\n",
    "DATA_DIR = ...\n",
    "DATA_MOD_DIR = ... # I copy it to another dir next to the original so I don't mess up the original.\n",
    "\n",
    "def get_classes():\n",
    "    # Edit to list (dict, ... whatever) of classes from your file names\n",
    "    return {\n",
    "                i: os.path.split(name)[-1] for i, name in\n",
    "                enumerate(sorted(glob(os.path.join(DATA_DIR, 'test', '*'))))\n",
    "           }\n",
    "\n",
    "def make_data_mod(files_per_class, refresh):\n",
    "    if os.path.exists(DATA_MOD_DIR) and not refresh:\n",
    "        return\n",
    "\n",
    "    if os.path.exists(DATA_MOD_DIR):\n",
    "        rmtree(DATA_MOD_DIR)\n",
    "    \n",
    "    for name in get_classes().values():\n",
    "        os.makedirs(os.path.join(DATA_MOD_DIR, name))\n",
    "        files_to_copy = glob(os.path.join(DATA_DIR, '...'))\n",
    "        for f in files_to_copy:\n",
    "            copy(f, os.path.join(DATA_MOD_DIR, name))\n",
    "    return            \n",
    "\n",
    "#make_data_mod(25, refresh=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 1028\n",
    "dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Above has a validation split which you probably want to use, again I do not because mine came them pre-split\n",
    "\n",
    "\n",
    "pretrained.model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, RAW_IMAGE_CHANNELS),\n",
    "    pooling='max',\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "\"\"\"\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "    input_shape=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, RAW_IMAGE_CHANNELS),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='max'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    # I haven't done it myself, but I'm pretty sure you can resize here\n",
    "    # You could also build that yourself into the dataset_mod function though, would save you some processing in the long run.\n",
    "])\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(525, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "train_history = model.fit(\n",
    "    dataset_train, # Will only load 1 batch into memory at a time as defined above\n",
    "    steps_per_epoch=len(dataset_train),\n",
    "    validation_data=dataset_valid,\n",
    "    validation_steps=len(dataset_valid),\n",
    "    epochs=50,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:37:46.458296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70435 files belonging to 2 classes.\n",
      "Using 56348 files for training.\n",
      "Using 14087 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:37:52.258367: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:37:53.473975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [56348]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-18 19:37:53.474470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [56348]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import rmtree, copy\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_DIR = '/home/steve/Desktop/skin_cancer_detector/full_training_data/'\n",
    "DATA_MOD_DIR = ... # I copy it to another dir next to the original so I don't mess up the original.\n",
    "RAW_IMAGE_HEIGHT = 299\n",
    "RAW_IMAGE_WIDTH = 299\n",
    "RAW_IMAGE_CHANNELS = 3\n",
    "dropout = 0.2\n",
    "\n",
    "\"\"\"\n",
    "def get_classes():\n",
    "    # Edit to list (dict, ... whatever) of classes from your file names\n",
    "    return {\n",
    "                i: os.path.split(name)[-1] for i, name in\n",
    "                enumerate(sorted(glob(os.path.join(DATA_DIR, 'test', '*'))))\n",
    "           }\n",
    "\n",
    "def make_data_mod(files_per_class, refresh):\n",
    "    if os.path.exists(DATA_MOD_DIR) and not refresh:\n",
    "        return\n",
    "\n",
    "    if os.path.exists(DATA_MOD_DIR):\n",
    "        rmtree(DATA_MOD_DIR)\n",
    "    \n",
    "    for name in get_classes().values():\n",
    "        os.makedirs(os.path.join(DATA_MOD_DIR, name))\n",
    "        files_to_copy = glob(os.path.join(DATA_DIR, '...'))\n",
    "        for f in files_to_copy:\n",
    "            copy(f, os.path.join(DATA_MOD_DIR, name))\n",
    "    return            \n",
    "\n",
    "#make_data_mod(25, refresh=False)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 1028\n",
    "dataset_train, dataset_valid = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    #labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(299,299),\n",
    "    subset='both',\n",
    "    validation_split=0.2,\n",
    "    seed=209\n",
    ")\n",
    "# Above has a validation split which you probably want to use, again I do not because mine came them pre-split\n",
    "\n",
    "\n",
    "#pretrained_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "\n",
    "#        input_shape=(RAW_IMAGE_HEIGHT, RAW_IMAGE_WIDTH, RAW_IMAGE_CHANNELS),\n",
    "\n",
    "#        include_top=False,\n",
    "\n",
    "#        weights='imagenet',\n",
    "\n",
    "#        pooling='max'\n",
    "\n",
    "#    )\n",
    "\n",
    "\n",
    "pretrained_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(299, 299, 3),\n",
    "    #image_size=(299,299,3),\n",
    "    include_top=False,\n",
    "    pooling='max')  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "\n",
    "x = pretrained_model(inputs, training=False)\n",
    "\n",
    "x = tf.keras.layers.Dense(1028, activation='relu')(pretrained_model.output)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "base_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(299, 299, 3),\n",
    "    #image_size=(299,299,3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
    "\n",
    "#inputs = base_model.input\n",
    "#x = augment(inputs)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(base_model.output)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "#x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "# We're trying 2 this time\n",
    "#outputs = tf.keras.layers.Dense(2)(x)\n",
    "#model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_history = model.fit(\n",
    "    dataset_train, # Will only load 1 batch into memory at a time as defined above\n",
    "    #steps_per_epoch=len(dataset_train),\n",
    "    #validation_split = 0.2,\n",
    "    validation_data=dataset_valid,\n",
    "    validation_steps=len(dataset_valid),\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "model.save('skin_cancer_vgg19_19_Dec.2023.keras', overwrite=True)\n",
    "\n",
    "display('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
